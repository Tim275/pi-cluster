apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: fluentd
  namespace: logging
spec:
  interval: 15m
  chart:
    spec:
      chart: fluentd
      version: "0.3.9"
      sourceRef:
        kind: HelmRepository
        name: fluent
        namespace: logging
  install:
    remediation:
      retries: 3
  values:
    kind: DaemonSet

    # Disable Pod Security Policy
    rbac:
      create: true
      pspEnabled: false

    podSecurityPolicy:
      enabled: false

    # Skip health probes
    livenessProbe: null
    readinessProbe: null

    # Add an explicit nameOverride
    nameOverride: fluentd-logging

    # Increase resources
    resources:
      requests:
        cpu: 100m
        memory: 300Mi
      limits:
        cpu: 300m
        memory: 600Mi

    # Permission to access logs
    securityContext:
      privileged: true
      runAsUser: 0

    # Run on all nodes
    tolerations:
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule

    # Access container logs
    extraVolumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers

    extraVolumeMounts:
      - name: varlog
        mountPath: /var/log
      - name: varlibdockercontainers
        mountPath: /var/lib/docker/containers
        readOnly: true

    # Required plugins
    plugins:
      - fluent-plugin-rewrite-tag-filter
      - fluent-plugin-kubernetes_metadata_filter
      - fluent-plugin-grep

    configMapConfigs:
      fluent.conf: |-
        # Set to critical to drastically reduce logging
        <system>
          log_level critical
          suppress_repeated_stacktrace true
          ignore_repeated_log_interval 120
          emit_error_log_interval 120
        </system>

        # Container logs source with extremely conservative settings
        <source>
          @type tail
          path /var/log/containers/*.log
          # Aggressively exclude problematic logs
          exclude_path ["/var/log/containers/fluentd-*", "/var/log/containers/*logging*", "/var/log/containers/*elasticsearch*", "/var/log/containers/kibana*"]
          pos_file /var/log/fluentd-containers.log.pos
          tag raw.kubernetes.*
          read_from_head true
          # Strict parsing to avoid backslash issues
          <parse>
            @type regexp
            expression /^(?<time>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d+Z) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
            time_format %Y-%m-%dT%H:%M:%S.%NZ
          </parse>
        </source>

        # Initial aggressive filter for backslash hell
        <filter raw.kubernetes.**>
          @type grep
          <exclude>
            key log
            pattern /\\{4,}|pattern not matched/
          </exclude>
        </filter>

        # Safety valve - completely null output for any remaining problematic logs
        <filter raw.kubernetes.**>
          @type record_transformer
          enable_ruby true
          <record>
            log ${
              if !record["log"] 
                "-"
              elsif record["log"].to_s.include?("\\\\") || record["log"].to_s.include?("pattern not matched") || record["log"].to_s.length > 5000
                "[Log contained escape sequences or was too long - content removed]"
              else
                record["log"].to_s
              end
            }
          </record>
        </filter>

        # Add Kubernetes metadata
        <filter raw.kubernetes.**>
          @type kubernetes_metadata
          kubernetes_url https://#{ENV['KUBERNETES_SERVICE_HOST']}:#{ENV['KUBERNETES_SERVICE_PORT']}
          bearer_token_file /var/run/secrets/kubernetes.io/serviceaccount/token
          ca_file /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        </filter>

        # Route by namespace
        <match raw.kubernetes.**>
          @type rewrite_tag_filter
          <rule>
            key $.kubernetes.namespace_name
            pattern ^(.+)$
            tag k8s.namespace.$1
          </rule>
          <rule>
            key $.kubernetes.pod_name
            pattern ^(.+)$
            tag k8s.pod.$1
          </rule>
        </match>

        # Output to Elasticsearch 
        <match k8s.**>
          @type elasticsearch
          host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
          port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
          scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME']}"
          user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
          password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
          index_name ${tag}
          reconnect_on_error true
          request_timeout 30s
          
          <buffer tag>
            @type file
            path /var/log/fluentd-buffers/kubernetes.buffer
            chunk_limit_size 8M
            flush_mode interval
            flush_interval 10s
            flush_thread_count 1
            retry_max_interval 30
            retry_forever false
          </buffer>
        </match>

    env:
      - name: FLUENT_ELASTICSEARCH_HOST
        value: "elasticsearch-master"
      - name: FLUENT_ELASTICSEARCH_PORT
        value: "9200"
      - name: FLUENT_ELASTICSEARCH_SCHEME
        value: "http"
      - name: FLUENT_ELASTICSEARCH_USER
        valueFrom:
          secretKeyRef:
            name: elasticsearch-credentials
            key: username
      - name: FLUENT_ELASTICSEARCH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: elasticsearch-credentials
            key: password
      # Critical environment variables to avoid recursion issues
      - name: FLUENT_LOG_LEVEL
        value: "critical"
      - name: FLUENT_CONTAINER_TAIL_EXCLUDE_PATH
        value: '["/var/log/containers/fluentd-*", "/var/log/containers/*logging*", "/var/log/containers/*fluentd*", "/var/log/containers/*elasticsearch*"]'
