apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: fluentd
  namespace: logging
spec:
  interval: 15m
  chart:
    spec:
      chart: fluentd
      version: "0.3.9"
      sourceRef:
        kind: HelmRepository
        name: fluent
        namespace: logging
  values:
    kind: DaemonSet

    # Einfaches Pod-Setup
    tolerations:
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule

    # Kritisch: Root-Berechtigungen für Log-Zugriff
    securityContext:
      privileged: true
      runAsUser: 0

    # Health Checks deaktivieren für einfacheres Setup
    livenessProbe: null
    readinessProbe: null

    # Ressourcenlimits
    resources:
      requests:
        cpu: 100m
        memory: 200Mi
      limits:
        cpu: 200m
        memory: 400Mi

    # Volume-Mounts für Log-Zugriff
    extraVolumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers

    extraVolumeMounts:
      - name: varlog
        mountPath: /var/log
      - name: varlibdockercontainers
        mountPath: /var/lib/docker/containers
        readOnly: true

    # Benötigte Plugins
    plugins:
      - fluent-plugin-kubernetes_metadata_filter

    # Die eigentliche Fluentd-Konfiguration
    configMapConfigs:
      fluent.conf: |-
        <system>
          # Minimalste Logging-Stufe, um Rekursion zu vermeiden
          log_level fatal
        </system>

        # Container-Logs einsammeln, eigene Logs ausschließen
        <source>
          @type tail
          path /var/log/containers/*.log
          exclude_path ["/var/log/containers/*fluentd*", "/var/log/containers/*elastic*"]
          pos_file /var/log/fluentd-containers.log.pos
          tag kubernetes.*
          read_from_head true
          <parse>
            @type regexp
            expression /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
            time_format %Y-%m-%dT%H:%M:%S.%NZ
            keep_time_key true
          </parse>
        </source>

        # Kubernetes-Metadaten hinzufügen
        <filter kubernetes.**>
          @type kubernetes_metadata
        </filter>

        # Direkt an Elasticsearch senden
        <match kubernetes.**>
          @type elasticsearch
          host "elasticsearch-master"
          port "9200"
          scheme "http"
          user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
          password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
          index_name "k8s-logs.${tag}.%Y%m%d"
          
          <buffer tag, time>
            @type file
            path /var/log/fluentd-buffer
            flush_mode interval
            flush_interval 10s
            flush_thread_count 1
            retry_type exponential_backoff
            retry_max_interval 30
            chunk_limit_size 2M
            total_limit_size 256M
            overflow_action block
          </buffer>
        </match>

    env:
      - name: FLUENT_ELASTICSEARCH_USER
        valueFrom:
          secretKeyRef:
            name: elasticsearch-credentials
            key: username
      - name: FLUENT_ELASTICSEARCH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: elasticsearch-credentials
            key: password
      - name: FLUENT_LOG_LEVEL
        value: "fatal" # Loggt nur kritische Fehler
