apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: logstash
  namespace: logging
spec:
  interval: 15m
  chart:
    spec:
      chart: logstash
      version: "7.17.3"
      sourceRef:
        kind: HelmRepository
        name: elastic
        namespace: logging
  install:
    timeout: 10m
  upgrade:
    timeout: 10m
  # Important: Use emptyDir instead of PVC
  values:
    replicas: 1
    image: "docker.elastic.co/logstash/logstash"
    imageTag: "7.17.3"

    # Use Deployment instead of StatefulSet
    kind: Deployment

    # Disable persistence to avoid PVC issues
    persistence:
      enabled: false

    # Reduced resource limits
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 512Mi

    # Fix securityContext to avoid "breaks non-root policy" error
    securityContext:
      runAsUser: null
      privileged: false

    podSecurityContext:
      runAsUser: null
      fsGroup: null

    # Mount temp volume for sincedb
    extraVolumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: logstash-data
        emptyDir: {}

    extraVolumeMounts:
      - name: varlog
        mountPath: /var/log
        readOnly: true
      - name: varlibdockercontainers
        mountPath: /var/lib/docker/containers
        readOnly: true
      - name: logstash-data
        mountPath: /usr/share/logstash/data

    # Fix volume mount name to match
    extraInitContainers:
      - name: init-sincedb
        image: busybox
        command:
          [
            "sh",
            "-c",
            "mkdir -p /usr/share/logstash/data/sincedb && chmod -R 777 /usr/share/logstash/data",
          ]
        securityContext:
          runAsUser: 0
        volumeMounts:
          - name: logstash-data
            mountPath: /usr/share/logstash/data

    extraEnv:
      - name: LS_JAVA_OPTS
        value: "-Xms256m -Xmx256m"
      - name: ELASTICSEARCH_USER
        valueFrom:
          secretKeyRef:
            name: elasticsearch-credentials
            key: username
      - name: ELASTICSEARCH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: elasticsearch-credentials
            key: password

    logstashConfig:
      logstash.yml: |
        http.host: "0.0.0.0"
        path.data: /usr/share/logstash/data
        path.logs: /usr/share/logstash/logs
        log.level: info
        pipeline.workers: 1
        pipeline.batch.size: 125

    logstashPipeline:
      logstash.conf: |
        input {
          file {
            path => "/var/log/containers/*.log"
            exclude => ["/var/log/containers/*fluentd*", "/var/log/containers/*logstash*", "/var/log/containers/*elastic*", "/var/log/containers/*kibana*"]
            sincedb_path => "/usr/share/logstash/data/sincedb"
            start_position => "beginning"
            codec => "json"
            tags => ["kubernetes"]
          }
        }

        filter {
          grok {
            match => { "path" => "/var/log/containers/%{DATA:pod_name}_%{DATA:namespace}_%{GREEDYDATA:container_name}\.log" }
            remove_field => ["path"]
          }
          
          if [log] =~ /\\{5,}/ {
            drop {}
          }
          
          mutate {
            add_field => {
              "kubernetes" => {
                "namespace" => "%{namespace}",
                "pod" => "%{pod_name}",
                "container" => "%{container_name}"
              }
            }
            remove_field => ["namespace", "pod_name", "container_name"]
          }
          
          date {
            match => ["time", "ISO8601"]
            remove_field => ["time"]
          }
        }

        output {
          elasticsearch {
            hosts => ["elasticsearch-master:9200"]
            user => "${ELASTICSEARCH_USER}"
            password => "${ELASTICSEARCH_PASSWORD}"
            index => "logs-%{+YYYY.MM.dd}"
          }
        }
